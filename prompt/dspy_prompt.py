from typing import List

import dspy

from config.config import OPENAI_API_KEY
from loader.save_load_db import similarity_search_qdrant_data, load_vector_db, get_context_db

# Cáº¥u hÃ¬nh OpenAI
lm = dspy.LM('openai/gpt-4o-mini',
             api_key=OPENAI_API_KEY,
             temperature=0)
dspy.configure(lm=lm)


# XÃ¡c Ä‘á»‹nh class cÃ¢u há»i
class Question(dspy.Signature):
    """Báº¡n lÃ  há»‡ thá»‘ng trÃ­ch xuáº¥t thÃ´ng tin tá»« tÃ i liá»‡u. CHá»ˆ sá»­ dá»¥ng thÃ´ng tin trong context Ä‘Æ°á»£c cung cáº¥p.

    NguyÃªn táº¯c tráº£ lá»i:
    1. TrÃ­ch dáº«n nguyÃªn vÄƒn tá»« tÃ i liá»‡u khi cÃ³ thá»ƒ
    2. Náº¿u khÃ´ng cÃ³ nguyÃªn vÄƒn, diá»…n Ä‘áº¡t sÃ¡t nghÄ©a nháº¥t
    3. LuÃ´n kÃ¨m trÃ­ch dáº«n nguá»“n chÃ­nh xÃ¡c cho tá»«ng pháº§n cá»§a cÃ¢u tráº£ lá»i Ä‘Æ°a ra
    4. Tuyá»‡t Ä‘á»‘i khÃ´ng thÃªm thÃ´ng tin khÃ´ng cÃ³ trong context"""

    context: str = dspy.InputField(
        prefix="[TÃ€I LIá»†U NGUá»’N]\n",
        # format=lambda x: "\n".join([f"â— {item}" for item in x.split("\n")])
    )
    question: str = dspy.InputField(prefix="[CÃ‚U Há»I] ")
    history: str = dspy.InputField(prefix="[Lá»ŠCH Sá»¬ CHAT] ", default="")
    answer: str = dspy.OutputField(
        desc="""TRáº¢ Lá»œI PHáº¢I:
        - Báº¯t Ä‘áº§u báº±ng "Theo tÃ i liá»‡u..." náº¿u cÃ³ nguyÃªn vÄƒn
        - TrÃ­ch dáº«n chÃ­nh xÃ¡c (TÃªn tÃ i liá»‡u - Trang)
        - Äá»‹nh dáº¡ng: 
          1. Pháº§n tráº£ lá»i trá»±c tiáº¿p
          2. TrÃ­ch dáº«n nguá»“n
          3. Ngá»¯ cáº£nh liÃªn quan (náº¿u cáº§n)"""
    )


# Táº¡o module chatbot
class create_questions(dspy.Module):
    def __init__(self):
        super().__init__()
        self.predictor = dspy.ChainOfThought(Question)

    def forward(self, context: str, question: str, history: str) -> str:
        """Tráº£ lá»i cÃ¢u há»i dá»±a trÃªn ngá»¯ cáº£nh vÃ  lá»‹ch sá»­ há»™i thoáº¡

        """
        response = self.predictor(
            context=context,
            question=question,
            history=history
        )
        return response.answer


class FollowUpSignature(dspy.Signature):
    """Táº¡o 3 cÃ¢u há»i liÃªn quan Ä‘áº¿n cÃ¢u há»i vÃ  cÃ¢u tráº£ lá»i gáº§n Ä‘Ã¢y nháº¥t dá»±a trÃªn lá»‹ch sá»­ chat vÃ  context
        CÃ¢u há»i pháº£i liÃªn quan, khÃ´ng trÃ¹ng láº·p"""
    context: str = dspy.InputField(prefix="[TÃ i liá»‡u] ")
    history: str = dspy.InputField(prefix="[Lá»‹ch sá»­ há»™i thoáº¡i] ")
    questions: str = dspy.OutputField(
        desc="Danh sÃ¡ch 3 cÃ¢u há»i liÃªn quan logic, cÃ³ tÃ­nh káº¿ thá»«a, má»—i cÃ¢u há»i má»™t dÃ²ng",
        format=lambda x: "\n".join([f"{i + 1}. {q}" for i, q in enumerate(x)])
    )


class EnhancedChatBot(dspy.Module):
    def __init__(self):
        super().__init__()
        self.follow_up_predictor = dspy.ChainOfThought(FollowUpSignature)

    def forward(self, context: str, history: str) -> list:
        # Táº¡o cÃ¢u há»i follow-up
        prediction = self.follow_up_predictor(
            context=context,
            history=history
        )

        # Xá»­ lÃ½ káº¿t quáº£
        raw_questions = prediction.questions.split("\n")
        suggestions = [q.split(". ", 1)[1] for q in raw_questions if ". " in q]

        return suggestions[:3]  # Äáº£m báº£o chá»‰ tráº£ vá» 3 cÃ¢u há»i


chatbot = create_questions()
enhanced_bot = EnhancedChatBot()
db = load_vector_db()


def get_rseponse_with_dspy(user_question: str, history: str):
    # CÃ¢u há»i má»›i cá»§a ngÆ°á»i dÃ¹ng
    pdf_context = get_context_db(db, user_question)
    # Gá»i chatbot Ä‘á»ƒ tráº£ lá»i
    print(pdf_context)
    response = chatbot.forward(context=pdf_context, question=user_question, history=history)
    # thÃªm vÃ o lá»‹ch sá»­
    history += f"User: {user_question} \n Bot: {response}"
    # Táº¡o cÃ¢u há»i follow-up
    suggestions = enhanced_bot.forward(
        context=pdf_context,
        history=history
    )
    return response, suggestions

# print(get_rseponse_with_dspy("GiÃ¡m Ä‘á»‘c cáº§n lÃ m gÃ¬?", ""))

# # Sá»­ dá»¥ng
# enhanced_bot = EnhancedChatBot()
#
# # Táº¡o cÃ¢u há»i follow-up
# suggestions = enhanced_bot.forward(
#     context=pdf_context,
#     history=history
# )
#
# print("\n=== Gá»¢I Ã CÃ‚U Há»I TIáº¾P THEO ===")
# for i, question in enumerate(suggestions, 1):
#     print(f"{i}. {question}")

# def get_context(db, query):
#     docs = similarity_search_qdrant_data(db, query, k=5)
#
#     context_items = []
#     for doc in docs:
#         meta = doc.metadata
#         source = f"{meta.get('title', 'KhÃ´ng rÃµ')}"
#         if 'page' in meta:
#             source += f" - Trang {int(meta['page']) + 1}"
#
#         context_items.append(
#             f"ğŸ“„ Ná»˜I DUNG: {doc.page_content}\n"
#             f"ğŸ·ï¸ NGUá»’N: {source}\n"
#             "â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•"
#         )
#
#     return "\n".join(context_items)

# # Khá»Ÿi táº¡o module chatbot
# chatbot = create_questions()
# history = ""
# db = load_vector_db()
#
# # CÃ¢u há»i má»›i cá»§a ngÆ°á»i dÃ¹ng
# user_question = "GiÃ¡m Ä‘á»‘c pháº£i lÃ m gÃ¬?"
# pdf_context = get_context(db, user_question)
#
# # Gá»i chatbot Ä‘á»ƒ tráº£ lá»i
# response = chatbot.forward(context=pdf_context, question=user_question, history=history)
#
# # In káº¿t quáº£
# print(response)
#
# # thÃªm vÃ o lá»‹ch sá»­
# history += f"User: {user_question} \n Bot: {response}"
